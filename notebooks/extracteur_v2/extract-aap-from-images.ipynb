{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37af9a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "from pdf2image import convert_from_path\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import dotenv\n",
    "import base64\n",
    "\n",
    "dotenv.load_dotenv(\"./streamlit_local/.env\")\n",
    "# Get the directory of the current script (e.g., app.py)\n",
    "# SCRIPT_DIR = Path(__file__).parent.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pdf_to_image(pdf_path, page_number, output_folder=\"temp\"):\n",
    "    \"\"\"\n",
    "    Convertit une page spécifique d'un PDF en image\n",
    "    \"\"\"\n",
    "    # Créer le dossier temporaire s'il n'existe pas\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Convertir la page spécifique en image\n",
    "    images = convert_from_path(pdf_path, first_page=page_number, last_page=page_number)\n",
    "    \n",
    "    if not images:\n",
    "        raise ValueError(f\"Aucune image trouvée pour la page {page_number}\")\n",
    "    \n",
    "    # Sauvegarder l'image temporaire\n",
    "    image_path = os.path.join(output_folder, f\"page_{page_number}.jpg\")\n",
    "    images[0].save(image_path, \"JPEG\")\n",
    "    \n",
    "    return image_path\n",
    "\n",
    "def describe_image_with_openai(image_path):\n",
    "    \"\"\"\n",
    "    Envoie une image à l'API OpenAI pour en obtenir une description\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Describe this image\"},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{image_file.read().encode('base64')}\"\n",
    "                            },\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0,\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bdccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion de la page PDF en image...\n",
      "Une erreur s'est produite: name 'pdf_to_image' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    pdf_path = \"./data/PU_P01_AAP07.pdf\"\n",
    "    page_number = 3\n",
    "    # api_key = input(\"Entrez votre clé API OpenAI: \")\n",
    "    \n",
    "    try:\n",
    "        # Étape 1: Convertir la page PDF en image\n",
    "        print(\"Conversion de la page PDF en image...\")\n",
    "        image_path = pdf_to_image(pdf_path, page_number)\n",
    "        \n",
    "        # Étape 2: Envoyer l'image à OpenAI pour description\n",
    "        print(\"Envoi de l'image à OpenAI pour description...\")\n",
    "        description = describe_image_with_openai(image_path)\n",
    "        \n",
    "        # Afficher le résultat\n",
    "        print(\"\\nDescription de la page:\")\n",
    "        print(description)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite: {str(e)}\")\n",
    "    # finally:\n",
    "        # Nettoyage: supprimer l'image temporaire\n",
    "        # if os.path.exists(image_path):\n",
    "        #     os.remove(image_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be63fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted list of questions and informational prompts from the provided form image:\n",
      "\n",
      "```json\n",
      "[\n",
      "    \"Q2.1 Project title (Max 10 words)\",\n",
      "    \"Q2.2 Project summary NOTE: this summary may be published on the OCEAN website and used to promote your project if successful. (Max 150 words)\",\n",
      "    \"Q2.3 Blue Planet Fund outcomes Which Blue Planet Fund outcome(s) does your project address? Select all that apply. \n",
      "        □ Marine Protected Areas (MPAs) and Other Effective Conservation Measures (OECMs)\n",
      "        □ Illegal, Unreported, and Unregulated Fishing (IUU)\n",
      "        □ International and large-scale fisheries\n",
      "        □ Solid waste and other forms of marine pollution\n",
      "        □ Critical marine habitats for coastal resilience\n",
      "        □ Small-scale fisheries management\n",
      "        □ Aquaculture\n",
      "        □ None of the above. If so, please tell us how you address protecting the marine environment.\",\n",
      "    \"Q2.4 Marine ecosystems Does your project have a direct focus on any of the following marine ecosystem(s)? Select all that apply.\n",
      "        □ Coral reefs\n",
      "        □ Intertidal forests and shrublands (e.g., mangroves)\n",
      "        □ Seagrass meadows\n",
      "        □ Kelp forests\n",
      "        □ Shellfish beds & reefs\n",
      "        □ Coastal inlets, riverine estuaries and bays, coastal lakes and lagoons\n",
      "        □ Coastal salt marsh or reedbed\n",
      "        □ Ocean waters\n",
      "        □ Deep sea floors\n",
      "        □ Anthropogenic marine biome (artificial structures, marine aquafarms)\n",
      "        □ Shorelines (rocky, muddy, sandy, boulder & cobble)\n",
      "        □ Coastal Shrublands and Grasslands\n",
      "        □ No direct focus on specific ecosystem(s)\",\n",
      "    \"Q2.5 Project region What region will your project work in? Select all that apply.\"\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "image_path=\"./temp/image_form.png\"\n",
    "\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    # Encoder l'image en base64\n",
    "    base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "system_prompt=\"\"\"\n",
    "            I have a collection of form images that include questions in different configurations. The forms may include:\n",
    "\n",
    "            Straight and direct interrogative questions:\n",
    "            Examples:\n",
    "\n",
    "            \"Where is the project located?\"\n",
    "            \"Who are the target beneficiaries?\"\n",
    "            Informational expectations presented in a descriptive (non-interrogative) style:\n",
    "            Examples:\n",
    "\n",
    "            \"Project description\"\n",
    "            \"Expected outcomes\"\n",
    "            Questions that include an explanation, sub-questions, or multiple choice items as guidance:\n",
    "            Examples:\n",
    "\n",
    "            Example 1: Project Justification and Beneficiary\n",
    "            \"Problem Analysis (max. 600 words)\n",
    "            Please provide:\n",
    "            a description of the current situation or issue related to the project (background, geographic region, and beneficiaries, etc).\n",
    "            an analysis of the problem the project is trying to address. Develop a Problem Tree by defining the core problem and identifying its causes and effects. The description must be clearly linked to the project’s objectives and how the project will address the problem.\"\n",
    "            Example 2: Date of Submission\n",
    "            \"When will the project be submitted to the donor?\n",
    "            Is the submission date aligned with the donor’s deadlines?\n",
    "            Are there any internal deadlines for reviews before submission?\n",
    "            Would a timeline graphic of submission milestones be helpful?\"\n",
    "            Example 3: Blue Planet Fund outcomes\n",
    "            \"Which Blue Planet Fund outcome(s) does your project address? Select all that apply.\n",
    "            □ Marine Protected Areas (MPAs) and Other Effective Conservation Measures (OECMs)\n",
    "            □ Illegal, Unreported, and Unregulated Fishing (IUU)\n",
    "            □ International and large-scale fisheries\n",
    "            □ Solid waste and other forms of marine pollution\n",
    "            □ Critical marine habitats for coastal resilience\n",
    "            □ Small-scale fisheries management\n",
    "            □ Aquaculture\n",
    "            □ None of the above. If so, please tell us how you address protecting the marine environment.\"\n",
    "            Your task is to process the provided images of these forms, extract all the questions (regardless of their configuration), and output a JSON-like list of strings. Each string in the list should represent one question or one key informational prompt extracted from the image.\n",
    "\n",
    "            The expected output format should be like this:\n",
    "            [\n",
    "                \"Question 1 extracted from the image + multiple choice options +  relevant information notes\",\n",
    "                \"Question 2 extracted from the image + multiple choice options +  relevant information notes\",\n",
    "                \"Question 3 extracted from the image + multiple choice options +  relevant information notes\"\n",
    "                ...\n",
    "            ]\n",
    "\n",
    "            Make sure to:\n",
    "            Accurately extract and capture the essence of the question or informational prompt from every form, even if the wording is not in a strictly interrogative style.\n",
    "            Include  multiple choice items, sub-questions or any guidance details if they are integral to the overall question prompt.\n",
    "            Preserve the order of appearance as found in the images (if applicable) or indicate if the order is arbitrary.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "model=\"meta-llama/llama-4-maverick:free\"\n",
    "model=\"mistralai/mistral-small-3.1-24b-instruct:free\"\n",
    "completion = client.chat.completions.create(  \n",
    "  model=model,\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Extract the questions from this form\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {                                \n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "      }\n",
    "  ],\n",
    "  temperature=0,\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c21c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "    \"Q2.1 Project title (Max 10 words)\",\n",
      "    \"Q2.2 Project summary NOTE: this summary may be published on the OCEAN website and used to promote your project if successful. (Max 150 words)\",\n",
      "    \"Q2.3 Blue Planet Fund outcomes Which Blue Planet Fund outcome(s) does your project address? Select all that apply. \n",
      "        □ Marine Protected Areas (MPAs) and Other Effective Conservation Measures (OECMs)\n",
      "        □ Illegal, Unreported, and Unregulated Fishing (IUU)\n",
      "        □ International and large-scale fisheries\n",
      "        □ Solid waste and other forms of marine pollution\n",
      "        □ Critical marine habitats for coastal resilience\n",
      "        □ Small-scale fisheries management\n",
      "        □ Aquaculture\n",
      "        □ None of the above. If so, please tell us how you address protecting the marine environment.\",\n",
      "    \"Q2.4 Marine ecosystems Does your project have a direct focus on any of the following marine ecosystem(s)? Select all that apply.\n",
      "        □ Coral reefs\n",
      "        □ Intertidal forests and shrublands (e.g., mangroves)\n",
      "        □ Seagrass meadows\n",
      "        □ Kelp forests\n",
      "        □ Shellfish beds & reefs\n",
      "        □ Coastal inlets, riverine estuaries and bays, coastal lakes and lagoons\n",
      "        □ Coastal salt marsh or reedbed\n",
      "        □ Ocean waters\n",
      "        □ Deep sea floors\n",
      "        □ Anthropogenic marine biome (artificial structures, marine aquafarms)\n",
      "        □ Shorelines (rocky, muddy, sandy, boulder & cobble)\n",
      "        □ Coastal Shrublands and Grasslands\n",
      "        □ No direct focus on specific ecosystem(s)\",\n",
      "    \"Q2.5 Project region What region will your project work in? Select all that apply.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "resp=completion.choices[0].message.content\n",
    "start=resp.find('```json')+7\n",
    "end=resp.find(\"\"\"]\n",
    "```\"\"\")+1\n",
    "resp=resp[start: end]\n",
    "print(resp)\n",
    "\n",
    "import json\n",
    "\n",
    "#json.loads(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48aa247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\n",
    "    \"Q2.1 Project title (Max 10 words)\",\n",
    "    \"Q2.2 Project summary NOTE: this summary may be published on the OCEAN website and used to promote your project if successful. (Max 150 words)\",\n",
    "    \"\"\"Q2.3 Blue Planet Fund outcomes Which Blue Planet Fund outcome(s) does your project address? Select all that apply. \n",
    "        □ Marine Protected Areas (MPAs) and Other Effective Conservation Measures (OECMs)\n",
    "        □ Illegal, Unreported, and Unregulated Fishing (IUU)\n",
    "        □ International and large-scale fisheries\n",
    "        □ Solid waste and other forms of marine pollution\n",
    "        □ Critical marine habitats for coastal resilience\n",
    "        □ Small-scale fisheries management\n",
    "        □ Aquaculture\n",
    "        □ None of the above. If so, please tell us how you address protecting the marine environment.\"\"\",\n",
    "    \"\"\"Q2.4 Marine ecosystems Does your project have a direct focus on any of the following marine ecosystem(s)? Select all that apply.\n",
    "        □ Coral reefs\n",
    "        □ Intertidal forests and shrublands (e.g., mangroves)\n",
    "        □ Seagrass meadows\n",
    "        □ Kelp forests\n",
    "        □ Shellfish beds & reefs\n",
    "        □ Coastal inlets, riverine estuaries and bays, coastal lakes and lagoons\n",
    "        □ Coastal salt marsh or reedbed\n",
    "        □ Ocean waters\n",
    "        □ Deep sea floors\n",
    "        □ Anthropogenic marine biome (artificial structures, marine aquafarms)\n",
    "        □ Shorelines (rocky, muddy, sandy, boulder & cobble)\n",
    "        □ Coastal Shrublands and Grasslands\n",
    "        □ No direct focus on specific ecosystem(s)\"\"\",\n",
    "    \"Q2.5 Project region What region will your project work in? Select all that apply.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01864f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(\"./streamlit_local/.env\")\n",
    "\n",
    "def compare_with_cosine_similarity(model, text1, text2):    \n",
    "\n",
    "    # encode queries and passages\n",
    "    text1_embeddings = model.encode([text1], normalize_embeddings=True)\n",
    "    text2_embeddings = model.encode([text2], normalize_embeddings=True)\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    return util.cos_sim(text1_embeddings, text2_embeddings)\n",
    "\n",
    "\n",
    "def compare_with_llm(text1, text2):\n",
    "    client = OpenAI()\n",
    "        \n",
    "    system_prompt=\"\"\"\n",
    "        You are a semantic duplicate detector. Given two input texts A and B, determine whether they express the same meaning and therefore should be considered duplicates.  \n",
    "\n",
    "        • Your answer must include:\n",
    "        1. a label: SAME” or “NOT_SAME\n",
    "        2. a confidence score from 0.0 (no confidence) to 1.0 (maximum confidence)        \n",
    "\n",
    "        • Consider variations such as:\n",
    "        – truncation (one text is an excerpt of the other)\n",
    "        – paraphrase (different wording but same intent)\n",
    "        – re‑ordering or added optional detail\n",
    "        – synonyms, but pay attention to changes in scope or emphasis\n",
    "        – differences in question verbs or focus words that alter meaning\n",
    "\n",
    "        • Strictly label as SAME only if their core meaning and intent coincide—even if one is shorter, truncated, or worded differently.\n",
    "\n",
    "        Output a json schema\n",
    "\n",
    "    \"\"\"\n",
    "    user_prompt=f\"\"\"\n",
    "        Text 1: {text1}\n",
    "        Text 2: {text2}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o4-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],        \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def compare_with_fuzzy(text1, text2):\n",
    "    return fuzz.token_set_ratio(text1[:200], text2[:200])            \n",
    "\n",
    "\n",
    "minilm= SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", trust_remote_code=True, device=\"cpu\"),\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba7576b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000]])\n",
      "100\n",
      "{\"label\":\"SAME\",\"confidence\":1.0}\n"
     ]
    }
   ],
   "source": [
    "src_text=\"\"\"\n",
    "    I have read the Guidance, including the “Complete Guidance for \n",
    "    Applicants”, “Gender Equality, Disability and Social Inclusion \n",
    "    Guidance”, “Finance Guidance” and “Monitoring, Evaluation and \n",
    "    Learning Guidance”\n",
    "\"\"\"\n",
    "\n",
    "extracted_text=\"\"\"\n",
    "    I have read the Guidance, including the “Complete Guidance for Applicants”, \n",
    "    “Gender Equality, Disability and Social Inclusion Guidance”, “Finance \n",
    "    Guidance” and “Monitoring, Evaluation and Learning Guidance”\n",
    "\"\"\"\n",
    "\n",
    "print(compare_with_cosine_similarity(model=minilm[0], text1=src_text, text2=extracted_text))\n",
    "print(compare_with_fuzzy(src_text, extracted_text))\n",
    "print(compare_with_llm(src_text, extracted_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
